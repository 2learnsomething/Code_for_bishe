{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import Str\n",
    "from genericpath import exists\n",
    "import string\n",
    "from tracemalloc import stop\n",
    "from turtle import left\n",
    "from matplotlib.pyplot import title\n",
    "from matplotlib.style import use\n",
    "import jieba\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from zhon import hanzi\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from price_preprocess import get_company_name_code, new_left_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_path = 'D:\\毕设code\\\\news_data_from2016to2021\\companies\\深交所A股列表_主板.xlsx'\n",
    "def get_company_name_code(company_path):\n",
    "    company_detail = pd.read_excel(company_path)\n",
    "    name_code = company_detail.loc[:, ['公司全称', 'A股代码', 'A股简称']]\n",
    "    #代码部分是数字所以还需要做一些处理,使用内置的zfill函数\n",
    "    name_code['A股代码'] = pd.DataFrame(\n",
    "        [str(code).zfill(6) for code in name_code['A股代码'].values],\n",
    "        columns=['A股代码'])\n",
    "    #股票简称支付中间存在空格\n",
    "    name_code['A股简称'] = pd.DataFrame(\n",
    "        [name.replace(' ', '') for name in name_code['A股简称'].values],\n",
    "        columns=['A股简称'])\n",
    "\n",
    "    return zip(name_code['公司全称'].values, name_code['A股代码'].values,\n",
    "               name_code['A股简称'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#新闻所在路径\n",
    "news_path = 'D:\\毕设code\\\\news_data_from2016to2021'\n",
    "#年份列表\n",
    "year_list = ['2016', '2017', '2018', '2019', '2020', '2021']\n",
    "#文件名称\n",
    "file_name = 'ER_NewsInfo.xlsx'\n",
    "#需要额外保存的列名\n",
    "columns_name = ['DeclareDate', 'Classify', 'Title', 'NewsContent', 'Symbol']\n",
    "#交易日数据\n",
    "trade_date_path = 'D:\\毕设code\\\\news_data_from2016to2021\\companies\\\\trade_cal_clean.csv'\n",
    "#中文停词\n",
    "chnstopword = 'D:\\chrome\\Listed-company-news-crawl-and-text-analysis-master\\src\\Leorio\\chnstopwords.txt'\n",
    "#储存最后使用的公司的路径\n",
    "company_final = 'D:\\毕设code\\\\news_data_from2016to2021\\companies\\\\final_use'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade_day(trade_day_path):\n",
    "    print('获取了交易日数据')\n",
    "    return pd.read_csv(trade_day_path)\n",
    "def date_trans(date):\n",
    "    date = pd.to_datetime(date)\n",
    "    return date.strftime('%Y-%m-%d')\n",
    "def company_list(tripule):\n",
    "    company_name, company_code, company_short = [], [], []\n",
    "    for elem in tripule:\n",
    "        company_name.append(elem[0])\n",
    "        company_code.append(elem[1])\n",
    "        company_short.append(elem[2])\n",
    "    print('获得了公司信息')\n",
    "    return company_name, company_code, company_short\n",
    "def get_news_data(year):\n",
    "    start_time = time.time()\n",
    "    news_name = os.path.join(news_path, str(year), file_name)\n",
    "    news_data = pd.read_excel(news_name)  #获取新闻资讯数据\n",
    "    end_time = time.time()\n",
    "    print(end_time-start_time)\n",
    "    news_data['DeclareDate'] = news_data['DeclareDate'].apply(\n",
    "        lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d'\n",
    "                                                                     ))\n",
    "    return news_data[columns_name]\n",
    "\n",
    "def get_specific_date_news(date, news_data):\n",
    "    date = date_trans(date)\n",
    "    return news_data[news_data['DeclareDate'] == date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让文本只保留汉字\n",
    "def is_chinese(uchar):\n",
    "    if uchar >= u'\\u4e00' and uchar <= u'\\u9fa5':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def format_str(content):\n",
    "    content_str = ''\n",
    "    for i in content:\n",
    "        if is_chinese(i):\n",
    "            content_str = content_str + i\n",
    "    return content_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_str(desstr, restr=''):\n",
    "    res = re.compile(\"[^\\u4e00-\\u9fa5^a-z^A-Z^0-9]\")\n",
    "    return res.sub(restr, desstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_braceket(text):\n",
    "    #title = re.sub('^《[\\u4e00-\\u9fa5_a-zA-Z0-9]+》','',title) 法律条令\n",
    "    text = re.sub('^([\\u4e00-\\u9fa5_a-zA-Z0-9]+)', '', text)\n",
    "    text = re.sub('^【[\\u4e00-\\u9fa5_a-zA-Z0-9]+】', '', text)\n",
    "    text = re.sub('^@[\\u4e00-\\u9fa5_a-zA-Z0-9]+', '', text)\n",
    "    return text\n",
    "def title_preprocess(title):\n",
    "    title_list = title.split()\n",
    "    title_list = [\n",
    "        remove_braceket(title_constitution)\n",
    "        for title_constitution in title_list\n",
    "    ]\n",
    "    title_list = [\n",
    "        format_str(title_constitution) for title_constitution in title_list\n",
    "    ]\n",
    "    return ''.join(title_list)\n",
    "#todo，目前发现主要是链接，之后可能会有其他操作\n",
    "def content_preprocess(content):\n",
    "    return re.sub('^([a-zA-z]+://[^\\s]*)', '', content)\n",
    "def split_sentence(paragraph):\n",
    "    print('分句ing')\n",
    "    sentence_set = re.findall(hanzi.sentence, paragraph)\n",
    "    return sentence_set\n",
    "def news_preprocess(content):\n",
    "    \"\"\"去除中文的标点符号\n",
    "\n",
    "    Args:\n",
    "        content (str): 中文字符串\n",
    "\n",
    "    Returns:\n",
    "        [list]: 去除标点符号之后的句子列表\n",
    "    \"\"\"\n",
    "    content = content.rsplit('（', 1)[0]  #去掉'（文章来源：xxxx）'\n",
    "    content = content.replace('\\u3000', ' ')  #首先将所有的全角空格替换掉\n",
    "    content_split_list = content.split()  #此处只是得到段落，还需要处理\n",
    "    content_list = []\n",
    "    for paragraph in content_split_list:\n",
    "        sentence_set = split_sentence(paragraph)  #段落的句子集合，包含奇奇怪怪的比如emoji等符号\n",
    "        sentence_set = list(map(filter_str, sentence_set))  #去除奇怪符号\n",
    "        content_list += sentence_set  #这个地方事实上没有考虑段落这一关系，这个地方之后如有需要可以改\n",
    "        #content_list.append(sentence_set) 即可，就是段落区分，这个之后的处理也需要一点变化，先待定。\n",
    "    chinese_list = []  #一条资讯全部句子\n",
    "    for sentence in content_list:\n",
    "        chinese_list.append(format_str(sentence))\n",
    "    return chinese_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_company_news(company_name, company_code, company_short, date, news_data):\n",
    "    \"\"\"获取新闻标题，内容以及资讯分类等信息\n",
    "\n",
    "    Args:\n",
    "        company_name (str): 全称\n",
    "        company_code (str): 代码\n",
    "        company_short (str): 简称\n",
    "        date (date): 需要的某天资讯 \n",
    "        year (str): 某一年的资讯\n",
    "\n",
    "    Returns:\n",
    "        [tuple]: 需要的信息的元组\n",
    "    \"\"\"\n",
    "    #获取指定日期全部新闻\n",
    "    specific_date_news = get_specific_date_news(date, news_data)\n",
    "    #去除newscontent为空的数据行\n",
    "    specific_date_news = specific_date_news.dropna(subset=['NewsContent','Title'])\n",
    "    #对相关联股票代码这一列进行填充操作\n",
    "    specific_date_news = specific_date_news.fillna({'Symbol': '000000'})  \n",
    "    #index重置，这个很有必要\n",
    "    specific_date_news = specific_date_news.reset_index(drop=True)\n",
    "    # title列和newscontent列可能出现数字类型，这个需要进行处理\n",
    "    specific_date_news[['Title','NewsConten']] = specific_date_news[['Title','NewsContent']].astype(str)\n",
    "    news_title, news_content, news_classification = [], [], []\n",
    "    exists_news = False\n",
    "    #获取某公司的相关新闻\n",
    "    for idx in range(len(specific_date_news)):\n",
    "        if specific_date_news.loc[idx,'Title'].find(company_name) != -1 or \\\n",
    "            specific_date_news.loc[idx,'NewsContent'].find(company_name) != -1 or \\\n",
    "            specific_date_news.loc[idx,'Title'].find(company_code) != -1 or \\\n",
    "            specific_date_news.loc[idx,'NewsContent'].find(company_code) != -1 or \\\n",
    "            specific_date_news.loc[idx,'Title'].find(company_short) != -1 or \\\n",
    "            specific_date_news.loc[idx,'NewsContent'].find(company_short) != -1 or \\\n",
    "            company_code == specific_date_news.loc[idx,'Symbol']:\n",
    "            # 注意一下symbol列的情况。\n",
    "            title = title_preprocess(specific_date_news.loc[idx, 'Title'])\n",
    "            content = content_preprocess(specific_date_news.loc[idx,\n",
    "                                                                'NewsContent'])\n",
    "            news_title.append(title)\n",
    "            news_content.append(content)\n",
    "            news_classification.append(specific_date_news.loc[idx, 'Classify'])\n",
    "    if len(news_title) != 0:\n",
    "        exists_news = True\n",
    "    return exists_news, news_title, news_content, news_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_detail(company_name, company_code, company_short):\n",
    "    company = OrderedDict()\n",
    "    company['name'] = company_name\n",
    "    company['code'] = company_code\n",
    "    company['short'] = company_short\n",
    "    return company\n",
    "def maintain_relevent_news_single_year(year, company_final, trade_date_path):\n",
    "    tripule = get_company_name_code(company_path)\n",
    "    company_name, company_code, company_short = [], [], []\n",
    "    company_left = new_left_company(company_final)  #获取留下来的公式code\n",
    "    company_left_code = list(map(lambda x: x.replace('.csv', ''),\n",
    "                                 company_left))\n",
    "    #获取到留下的公司的代码，简称等信息\n",
    "    for elem in tripule:\n",
    "        if elem[1] in company_left_code:\n",
    "            company_name.append(elem[0])\n",
    "            company_code.append(elem[1])\n",
    "            company_short.append(elem[2])\n",
    "    #获取交易日数据\n",
    "    trade_day_ = trade_day(trade_date_path)\n",
    "    trade_day_['year'] = trade_day_['cal_date'].apply(\n",
    "        lambda x: str(x)[:4])  #获取年份\n",
    "    trade_day_['date'] = trade_day_['cal_date'].apply(\n",
    "        lambda x: date_trans(str(x)))\n",
    "    trade_day_data = trade_day_[trade_day_['year'] == str(year)]\n",
    "    trade_day_data = trade_day_data.reset_index(drop=True)  #获取指定年份的交易日数据\n",
    "    total_dict = OrderedDict()\n",
    "    news_data = get_news_data(year)\n",
    "    print('----开始----')\n",
    "    for index in range(len(trade_day_data)-2,len(trade_day_data)):\n",
    "        news_dict = OrderedDict()\n",
    "        is_open = trade_day_data.loc[index, 'is_open']  #获取该日期是否开市\n",
    "        news_dict['is_open'] = is_open\n",
    "        company_data = OrderedDict()\n",
    "        for i in range(len(company_code)):\n",
    "            company_dict = company_detail(company_name[i], company_code[i],\n",
    "                                          company_short[i])\n",
    "            exists_news, news_title, news_content, news_classification = single_company_news(\n",
    "                company_name[i], company_code[i], company_short[i],\n",
    "                trade_day_data.loc[index, 'date'], news_data)\n",
    "            company_dict['exists_news'] = exists_news\n",
    "            company_dict['title'] = news_title\n",
    "            company_dict['content'] = news_content\n",
    "            company_dict['classification'] = news_classification\n",
    "            company_data[company_code[i]] = company_dict\n",
    "        news_dict['company'] = company_data\n",
    "        total_dict[trade_day_data.loc[index, 'date']] = news_dict\n",
    "        print('完成{}的处理！'.format(trade_day_data.loc[index,'date']))\n",
    "\n",
    "    json_str = json.dumps(total_dict, indent=4)\n",
    "    with open(os.path.join('news_data_from2016to2021\\companies',\n",
    "                           str(year) + '_data.json'), 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "    print('----完成----')\n",
    "\n",
    "\n",
    "def maintain_five_year(year_list, company_final, trade_date_path):\n",
    "    \"\"\"将五年的数据进行分类保存\n",
    "\n",
    "    Args:\n",
    "        year_list (list): 年份的列表，[2020,2021]这种\n",
    "        company_final (str): 路径\n",
    "        trade_date_path (str): 交易数据路径\n",
    "    \"\"\"\n",
    "    for year in year_list:\n",
    "        maintain_relevent_news_single_year(year, company_final,\n",
    "                                           trade_date_path)\n",
    "        print('完成一年的数据分类')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = [2018]\n",
    "maintain_five_year(year_list, company_final, trade_date_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.39613699913025\n"
     ]
    }
   ],
   "source": [
    "news_data = get_news_data(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 445396 entries, 0 to 445395\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   DeclareDate  445396 non-null  object\n",
      " 1   Classify     445396 non-null  object\n",
      " 2   Title        445396 non-null  object\n",
      " 3   NewsContent  445391 non-null  object\n",
      " 4   Symbol       150442 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 17.0+ MB\n"
     ]
    }
   ],
   "source": [
    "news_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2019-01-01\n",
       "1         2019-01-01\n",
       "2         2019-01-01\n",
       "3         2019-01-01\n",
       "4         2019-01-01\n",
       "             ...    \n",
       "445391    2019-12-30\n",
       "445392    2019-12-30\n",
       "445393    2019-12-30\n",
       "445394    2019-12-30\n",
       "445395    2019-12-30\n",
       "Name: DeclareDate, Length: 445396, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data['DeclareDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 444041 entries, 1355 to 445395\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   DeclareDate  444041 non-null  object\n",
      " 1   Classify     444041 non-null  object\n",
      " 2   Title        444041 non-null  object\n",
      " 3   NewsContent  444036 non-null  object\n",
      " 4   Symbol       149871 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 16.9+ MB\n"
     ]
    }
   ],
   "source": [
    "news_data = news_data.drop(index = news_data.loc[news_data['DeclareDate'] == '2019-01-02'].index)\n",
    "news_data.info()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44c4d7f837e44efbb06481c2ee89e900c04f72ee2558abe101764a1a3ac9135e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('bishe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
